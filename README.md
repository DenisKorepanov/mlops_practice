# mlops_practice

Practices for MLops course UrFU + SkillFactory
Module 1
Подробнее
Необходимо из создать простейший конвейер для автоматизации работы с моделью машинного обучения.
Отдельные этапы конвейера машинного обучения описываются в разных python–скриптах, которые потом соединяются в единую цепочку действий с помощью bash-скрипта.
Все файлы необходимо разместить в подкаталоге lab1 корневого каталога
Этапы:

Создайте python-скрипт (data_creation.py), который создает различные наборы данных, описывающие некий процесс (например, изменение дневной температуры). Таких наборов должно быть несколько, в некоторые данные можно включить аномалии или шумы. Часть наборов данных должны быть сохранены в папке “train”, другая часть в папке “test”. Одним из вариантов выполнения этого этапа может быть скачивание набора данных из сети, и разделение выборки на тестовую и обучающую. Учтите, что файл должен быть доступен и методы скачивания либо есть в ubuntu либо устанавливаются через pip в файле pipeline.sh
Создайте python-скрипт (data_preprocessing.py), который выполняет предобработку данных, например, с помощью sklearn.preprocessing.StandardScaler. Трансформации выполняются и над тестовой и над обучающей выборкой.
Создайте python-скрипт (model_preparation.py), который создает и обучает модель машинного обучения на построенных данных из папки “train”. Для сохранения модели в файл можно воспользоваться pickle (см. пример)
Создайте python-скрипт (model_testing.py), проверяющий модель машинного обучения на построенных данных из папки “test”.
Напишите bash-скрипт (pipeline.sh), последовательно запускающий все python-скрипты. При необходимости усложните скрипт. В результате выполнения скрипта на терминал в стандартный поток вывода печатается одна строка с оценкой метрики на вашей модели, например:
Model test accuracy is: 0.876
Настоятельно рекомендуем вам проверить работоспособность скрипта в окружении отличном от того в котором происходила разработка.

Module 2
Подробнее
Вам нужно разработать собственный конвейер автоматизации для проекта машинного обучения. Для этого вам понадобится виртуальная машина с установленным Jenkins, python и необходимыми библиотеками. В ходе выполнения практического задания вам необходимо автоматизировать сбор данных, подготовку датасета, обучение модели и работу модели.
Разработанный конвеер требуется выгрузить в файл. Так же все скрипты (этапы конвеера требуется сохранить)
Все файлы необходимо разместить в подкаталоге lab2 корневого каталога Этапы задания
Развернуть сервер с Jenkins, установить необходимое программное обеспечение для работы над созданием модели машинного обучения.
Выбрать способ получения данных (скачать из github, из Интернета, wget, SQL запрос, …).
Провести обработку данных, выделить важные признаки, сформировать датасеты для тренировки и тестирования модели, сохранить.
Создать и обучить на тренировочном датасете модель машинного обучения, сохранить в pickle или аналогичном формате.
Загрузить сохраненную модель на предыдущем этапе и проанализировать ее качество на тестовых данных.
Реализовать задания и конвеер. Связать конвеер с системой контроля версий. Сохранить конвеер.
Module 3
Подробнее
В практическом задание по модулю вам необходимо применить полученные знания по работе с docker (и docker-compose). Вам необходимо использовать полученные ранее знания по созданию микросервисов. В этом задании необходимо развернуть микросервис в контейнере докер. Например, это может быть модель машинного обучения, принимающая запрос по API и возвращающая ответ. Вариантом может быть реализация приложения на основе streamlit (https://github.com/korelin/streamlit_demo_app). Результаты работы над этой работой стоит поместить в подкаталог lab3 вашего корневого каталога репозитория. Что необходимо выполнить:

Подготовить python код для модели и микросервиса
Создать Docker file
Создать docker образ
Запустить docker контейнер и проверить его работу
Дополнительными плюсами будут:

Использование docker-compose
Автоматизация сборки образа привязка имени тэга к версии сборки (sha-коммита, имя ветки)
Деплой (загрузка) образа в хранилище артефактов например dockerhub
Module 4
Подробнее
В практическом задании данного модуля вам необходимо продемонстрировать навыки практического использования утилиты dvc для работы с данными. В результате выполнения этих заданий вы выполните все основные операции с dvc и закрепите полученные теоретические знания практическими действиями.

Этапы задания:

Создайте папку lab4 в корне проекта.
Установите git и dvc. Настройте папку проекта для работы с git и dvc.
Настройте удаленное хранилище файлов, например на Google Disk или S3.
Создайте датасет, например, о пассажирах “Титаника” catboost.titanic().
Модифицируйте датасет, в котором содержится информация о классе (“Pclass”), поле (“Sex”) и возрасте (“Age”) пассажира. Сделайте коммит в git и push в dvc.
Создайте новую версию датасета, в котором пропущенные (nan) значения в поле “Age” будут заполнены средним значением. Сделайте коммит в git и push в dvc.
Создайте новый признак с использованием one-hot-encoding для строкового признака “Пол” (“Sex”). Сделайте коммит в git и push в dvc.
Выполните переключение между всеми созданными версиями датасета.
При правильном выполнении задания и вас появится git репозиторий с опубликованной метаинформацией и папка на Google Disk, в которой хранятся различные версии датасетов. Вам необходимо подготовить отчет в тех функциональностях которые вы настроили. Дополнительно можно настроить DAG, запуск и версионирование экспериментов, например, с использованием Hydra.

В постановке задачи используется датасет из конкурса “Titanic Disaster”, однако вы можете использовать свои наборы данных, в этом случае в п.п.4-8 необходимо использовать информацию и признаки из вашего датасета.

Module 6
Подробнее
Тестирование качества работы моделей машинного обучения
Цель задания: применить средства автоматизации тестирования python для автоматического тестирования качества работы модели машинного обучения на различных датасетах. Результаты размещаются в каталоге lab5.

Этапы задания:

Создать три датасета с «качественными» данными, на которых можно обучить простую модель линейной регрессии, например
image clean data

На одном из этих датасетов обучить модель линейной регрессии
Создать датасет с шумом в данных, например
image clean data

Провести тестирование работы модели на разных датасетах с использованием pytest, анализируя качество предсказания, обнаружить проблему на датасете с шумами.
Критерии: данное задание необходимо полностью выполнить в виде jupyter ноутбука и предоставить его на проверку.

Подсказка: вы можете записать содержимое ячейки jupyter ноутбука в отдельный файл с помощью команды

%%writefile”имя файла”

А также можете выполнить любую linux команду прямо из ячейки jupyter ноутбука, с помощью синтаксиса

! “имя команды”
